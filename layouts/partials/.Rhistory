comp = contrast(m1, method = list("Star vs. AN combined" = c(1,-0.5, -0.5)),
adjust = "none", type="response")
comp
confint(comp)
#plot
# Calculate means and standard errors
summary_df <- df_r %>%
group_by(group) %>%
summarise(mean_click = mean(click),
se_click = sd(click) / sqrt(n()),
.groups = "drop") # Drop grouping
# Make the plot
ggplot(summary_df, aes(x = group, y = mean_click, fill=group)) +
geom_bar(stat = "identity", alpha = 0.7) +
geom_errorbar(aes(ymin = mean_click - se_click, ymax = mean_click + se_click),
width = 0.2, color = "black") +
ylab("Mean Clicks") +
ggtitle("Mean Clicks by Group with Error Bars") +
theme_minimal()
library(scales)
library(dplyr)
# Calculate mean click-through rates for each group
means <- df_r %>% group_by(group) %>% summarise(mean_click = mean(click))
x<-ggplot(df_r, aes(x=group, y=click, fill=group)) +
geom_bar(stat="summary", position = "dodge", width = 0.8) +
stat_summary(fun.data=mean_se, geom="errorbar", position="dodge", width=0.1, color="black", size=.45) +
geom_text(data=means, aes(y=0.051, label=scales::percent(mean_click)), vjust=0, size=5) +xlab("") +
ylab("Click-Through Rate") +
expand_limits(y=c(0,0.051)) + # Extend y axis to include labels
theme_minimal() +
scale_y_continuous(labels = scales::percent, n.breaks = 5) +
scale_fill_manual(values=c("#FBDA44","#60ABFB", "#8EDAF0"), name="Rating Symbol") +
theme(text = element_text(size = 15)) +
theme(axis.text = element_text(size = 14)) +
theme(legend.position="bottom") +
theme(legend.text=element_text(size=14), legend.title=element_text(size=13)) +
theme(panel.grid = element_blank()) # Remove grid lines
ggsave("test1.png",x,device=png, dpi=1200)
library(ggpattern)
install.packages("ggpattern")
library(ggpattern)
# Your ggplot command, modified to use ggpattern for the third group
ggplot(df_r, aes(x=group, y=click)) +
geom_bar_pattern(aes(pattern = group),
pattern_fill = "black",
pattern_colour = NA,
pattern_alpha = 0.5,
pattern_density = 0.1,
pattern_spacing = 0.02,
pattern_key_scale_factor = 1,
stat="summary", position = "dodge", width = 0.8) +
stat_summary(fun.data=mean_se, geom="errorbar", position="dodge", width=0.1, color="black", size=.45) +
geom_text(data=means, aes(y=0.051, label=scales::percent(mean_click)), vjust=0, size=5) +xlab("") +
ylab("Click-Through Rate") +
expand_limits(y=c(0,0.051)) + # Extend y axis to include labels
theme_minimal() +
scale_y_continuous(labels = scales::percent, n.breaks = 5) +
scale_fill_manual(values=c("#FBDA44","#60ABFB", "#8EDAF0"), name="Rating Symbol") +
theme(text = element_text(size = 15)) +
theme(axis.text = element_text(size = 14)) +
theme(legend.position="bottom") +
theme(legend.text=element_text(size=14), legend.title=element_text(size=13)) +
theme(panel.grid = element_blank())
x<-ggplot(df_r, aes(x=group, y=click, fill=group)) +
geom_bar(stat="summary", position = "dodge", width = 0.8) +
stat_summary(fun.data=mean_se, geom="errorbar", position="dodge", width=0.1, color="black", size=.45) +
geom_text(data=means, aes(y=0.051, label=scales::percent(mean_click)), vjust=0, size=5) +xlab("") +
ylab("Click-Through Rate") +
expand_limits(y=c(0,0.051)) + # Extend y axis to include labels
theme_minimal() +
scale_y_continuous(labels = scales::percent, n.breaks = 5) +
scale_fill_manual(values=c("#FBDA44","#60ABFB", "#878A8B"), name="Rating Symbol") +
theme(text = element_text(size = 15)) +
theme(axis.text = element_text(size = 14)) +
theme(legend.position="bottom") +
theme(legend.text=element_text(size=14), legend.title=element_text(size=13)) +
theme(panel.grid = element_blank()) # Remove grid lines
ggsave("test1.png",x,device=png, dpi=1200)
ggplot(df_r, aes(x=group, y=click, fill=group)) +
geom_bar(stat="summary", position = "dodge", width = 0.8) +
stat_summary(fun.data=mean_se, geom="errorbar", position="dodge", width=0.1, color="black", size=.45) +
geom_text(data=means, aes(y=0.051, label=scales::percent(mean_click)), vjust=0, size=5) +xlab("") +
ylab("Click-Through Rate") +
expand_limits(y=c(0,0.051)) + # Extend y axis to include labels
theme_minimal() +
scale_y_continuous(labels = scales::percent, n.breaks = 5) +
scale_fill_manual(values=c("#FBDA44","#60ABFB", "#878A8B"), name="Rating Symbol") +
theme(text = element_text(size = 15)) +
theme(axis.text = element_text(size = 14)) +
theme(legend.position="right") +
theme(legend.text=element_text(size=14), legend.title=element_text(size=13)) +
theme(panel.grid = element_blank()) # Remove grid lines
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(Hmisc)
library(dplyr)
library(haven)
library(rstatix)
library(car)
library(Matrix)
library(lme4)
library(emmeans)
library(aod)
library(ez)
library(effectsize)
library(interactions)
# 1) Preparing the data
# 	1.1) Loading the raw data and removing duplicate IP subjects
#	  1.2) Exclusions based on pre-registration
#	  1.3) Cleaning the raw data â€” creating and naming the variables
# 	1.4) Setting up the variables for analysis and creating the main data table
# 2) Checking Demographics
# 3) Conducting Main Analysis
#	  3.1) Get Descriptive Statistics and Plots
#	  3.2) Anova Analysis
# Set your working directory to be the folder in which you saved the data file.
#setwd("file pathname")
# Reading the data.
# Load the qualtrics data containing the responses.
qualtrics_data <- read_csv("data.csv")
#Removing the first two rows (the "import" rows)
data<-qualtrics_data[-c(1,2),]
# Removing Survey Previews
datax <- data %>% filter(!data$DistributionChannel == "preview")
# Removing incomplete responses (will use last survey question to check)
datay<-datax[which(!is.na(datax$Q59.4)),]
# Removing participants with duplicate IP addresses
dataz<-datay[!(duplicated(datay$IPAddress) | duplicated(datay$IPAddress, fromLast = TRUE)), ]
#colnames(dataz)
## Removing additional columns
data1<-dataz[,-c(1:5,7:42,322:325)]
#colnames(data1)
#Changing format of all variables to numeric except the character variables
data1[,-c(280:281)]<- as.data.frame(apply(data1[,-c(280:281)], 2, as.numeric))
#Transforming data structure format
data1<-data.table(data1)
# Next, Per pre-registration, I will filter out participants who were +/- 3 standard deviations above and below the mean of the log total time. I will log transform the variables first and then exclude by 3 standard deviations.
data1$totaltime<-data1$`Duration (in seconds)`
data1$logtotaltime<-log(data1$totaltime)
data3<-data1[which((data1$logtotaltime<=mean(data1$logtotaltime)+3*sd(data1$logtotaltime))&(data1$logtotaltime>=mean(data1$logtotaltime)-3*sd(data1$logtotaltime))),]
#Open ended response
data3$Open_ended<-as.character(data3$Q59.5)
#Assigning each subject an ID number
data3$ID <- as_factor(1:nrow(data3))
#age
data3$age<-(data3$Q59.1)
#gender (1 is female or non-binary and 0 is male)
data3$Gender<-data3$Q59.2
#income and log income of participants
data3$income=(15000 + (data3$Q59.3-1)*10000)
data3$logincome<-log(data3$income)
#education
data3$education<-data3$Q59.4
#using education to obtain years of education
data3$years_education<-8
data3[which(data3$Q59.4==2),]$years_education<-12
data3[which(data3$Q59.4==3),]$years_education<-13
data3[which(data3$Q59.4==4),]$years_education<-14
data3[which(data3$Q59.4==5),]$years_education<-16
data3[which(data3$Q59.4==6),]$years_education<-18
data3[which(data3$Q59.4==7),]$years_education<-21
data3[which(data3$Q59.4==8),]$years_education<-19
#creating duplicate datasets for the within subjects factor for one of the between subjects conditions, i.e. Visually Incomplete Stars
dataS<-data3[Contour=="Present"]
dataN<-data3[Contour=="Present"]
dataS$Format<-"Star"
dataN$Format<-"Numeric"
#creating duplicate datasets for the within subjects factor for one of the between subjects conditions, i.e. Visually Complete Stars
dataXS<-data3[Contour=="Absent"]
dataXN<-data3[Contour=="Absent"]
dataXS$Format<-"Star"
dataXN$Format<-"Numeric"
#creating 17 duplicate datasets for each of the four datasets created above.
dataS1<-dataS
dataS2<-dataS
dataS3<-dataS
dataS4<-dataS
dataS5<-dataS
dataS6<-dataS
dataS7<-dataS
dataS8<-dataS
dataS9<-dataS
dataS10<-dataS
dataS11<-dataS
dataS12<-dataS
dataS13<-dataS
dataS14<-dataS
dataS15<-dataS
dataS16<-dataS
dataS17<-dataS
dataN1<-dataN
dataN2<-dataN
dataN3<-dataN
dataN4<-dataN
dataN5<-dataN
dataN6<-dataN
dataN7<-dataN
dataN8<-dataN
dataN9<-dataN
dataN10<-dataN
dataN11<-dataN
dataN12<-dataN
dataN13<-dataN
dataN14<-dataN
dataN15<-dataN
dataN16<-dataN
dataN17<-dataN
dataXS1<-dataXS
dataXS2<-dataXS
dataXS3<-dataXS
dataXS4<-dataXS
dataXS5<-dataXS
dataXS6<-dataXS
dataXS7<-dataXS
dataXS8<-dataXS
dataXS9<-dataXS
dataXS10<-dataXS
dataXS11<-dataXS
dataXS12<-dataXS
dataXS13<-dataXS
dataXS14<-dataXS
dataXS15<-dataXS
dataXS16<-dataXS
dataXS17<-dataXS
dataXN1<-dataXN
dataXN2<-dataXN
dataXN3<-dataXN
dataXN4<-dataXN
dataXN5<-dataXN
dataXN6<-dataXN
dataXN7<-dataXN
dataXN8<-dataXN
dataXN9<-dataXN
dataXN10<-dataXN
dataXN11<-dataXN
dataXN12<-dataXN
dataXN13<-dataXN
dataXN14<-dataXN
dataXN15<-dataXN
dataXN16<-dataXN
dataXN17<-dataXN
dataS1$estimate<-dataS1$Q6.2_1
dataS1$value<-1
dataS1$time<-dataS1$`Q6.1_Page Submit`
dataS2$estimate<-dataS2$Q7.2_1
dataS2$value<-1.25
dataS2$time<-dataS2$`Q7.1_Page Submit`
dataS3$estimate<-dataS3$Q8.2_1
dataS3$value<-1.5
dataS3$time<-dataS3$`Q8.1_Page Submit`
dataS4$estimate<-dataS4$Q9.2_1
dataS4$value<-1.75
dataS4$time<-dataS4$`Q9.1_Page Submit`
dataS5$estimate<-dataS5$Q10.2_1
dataS5$value<-2
dataS5$time<-dataS5$`Q10.1_Page Submit`
dataS6$estimate<-dataS6$Q11.2_1
dataS6$value<-2.25
dataS6$time<-dataS6$`Q11.1_Page Submit`
dataS7$estimate<-dataS7$Q12.2_1
dataS7$value<-2.5
dataS7$time<-dataS7$`Q12.1_Page Submit`
dataS8$estimate<-dataS8$Q13.2_1
dataS8$value<-2.75
dataS8$time<-dataS8$`Q13.1_Page Submit`
dataS9$estimate<-dataS9$Q14.2_1
dataS9$value<-3
dataS9$time<-dataS9$`Q14.1_Page Submit`
dataS10$estimate<-dataS10$Q15.2_1
dataS10$value<-3.25
dataS10$time<-dataS10$`Q15.1_Page Submit`
dataS11$estimate<-dataS11$Q16.2_1
dataS11$value<-3.5
dataS11$time<-dataS11$`Q16.1_Page Submit`
dataS12$estimate<-dataS12$Q17.2_1
dataS12$value<-3.75
dataS12$time<-dataS12$`Q17.1_Page Submit`
dataS13$estimate<-dataS13$Q18.2_1
dataS13$value<-4
dataS13$time<-dataS13$`Q18.1_Page Submit`
dataS14$estimate<-dataS14$Q19.2_1
dataS14$value<-4.25
dataS14$time<-dataS14$`Q19.1_Page Submit`
dataS15$estimate<-dataS15$Q20.2_1
dataS15$value<-4.5
dataS15$time<-dataS15$`Q20.1_Page Submit`
dataS16$estimate<-dataS16$Q21.2_1
dataS16$value<-4.75
dataS16$time<-dataS16$`Q21.1_Page Submit`
dataS17$estimate<-dataS17$Q22.2_1
dataS17$value<-5
dataS17$time<-dataS17$`Q22.1_Page Submit`
dataN1$estimate<-dataN1$Q42.2_1
dataN1$value<-1
dataN1$time<-dataN1$`Q42.1_Page Submit`
dataN2$estimate<-dataN2$Q43.2_1
dataN2$value<-1.25
dataN2$time<-dataN2$`Q43.1_Page Submit`
dataN3$estimate<-dataN3$Q44.2_1
dataN3$value<-1.5
dataN3$time<-dataN3$`Q44.1_Page Submit`
dataN4$estimate<-dataN4$Q45.2_1
dataN4$value<-1.75
dataN4$time<-dataN4$`Q45.1_Page Submit`
dataN5$estimate<-dataN5$Q46.2_1
dataN5$value<-2
dataN5$time<-dataN5$`Q46.1_Page Submit`
dataN6$estimate<-dataN6$Q47.2_1
dataN6$value<-2.25
dataN6$time<-dataN6$`Q47.1_Page Submit`
dataN7$estimate<-dataN7$Q48.2_1
dataN7$value<-2.5
dataN7$time<-dataN7$`Q48.1_Page Submit`
dataN8$estimate<-dataN8$Q49.2_1
dataN8$value<-2.75
dataN8$time<-dataN8$`Q49.1_Page Submit`
dataN9$estimate<-dataN9$Q50.2_1
dataN9$value<-3
dataN9$time<-dataN9$`Q50.1_Page Submit`
dataN10$estimate<-dataN10$Q51.2_1
dataN10$value<-3.25
dataN10$time<-dataN10$`Q51.1_Page Submit`
dataN11$estimate<-dataN11$Q52.2_1
dataN11$value<-3.5
dataN11$time<-dataN11$`Q51.1_Page Submit`
dataN12$estimate<-dataN12$Q53.2_1
dataN12$value<-3.75
dataN12$time<-dataN12$`Q53.1_Page Submit`
dataN13$estimate<-dataN13$Q54.2_1
dataN13$value<-4
dataN13$time<-dataN13$`Q54.1_Page Submit`
dataN14$estimate<-dataN14$Q55.2_1
dataN14$value<-4.25
dataN14$time<-dataN14$`Q55.1_Page Submit`
dataN15$estimate<-dataN15$Q56.2_1
dataN15$value<-4.5
dataN15$time<-dataN15$`Q56.1_Page Submit`
dataN16$estimate<-dataN16$Q57.2_1
dataN16$value<-4.75
dataN16$time<-dataN16$`Q57.1_Page Submit`
dataN17$estimate<-dataN17$Q58.2_1
dataN17$value<-5
dataN17$time<-dataN17$`Q58.1_Page Submit`
dataXS1$estimate<-dataXS1$Q24.2_1
dataXS1$value<-1
dataXS1$time<-dataXS1$`Q24.1_Page Submit`
dataXS2$estimate<-dataXS2$Q25.2_1
dataXS2$value<-1.25
dataXS2$time<-dataXS2$`Q25.1_Page Submit`
dataXS3$estimate<-dataXS3$Q26.2_1
dataXS3$value<-1.5
dataXS3$time<-dataXS3$`Q26.1_Page Submit`
dataXS4$estimate<-dataXS4$Q27.2_1
dataXS4$value<-1.75
dataXS4$time<-dataXS4$`Q27.1_Page Submit`
dataXS5$estimate<-dataXS5$Q28.2_1
dataXS5$value<-2
dataXS5$time<-dataXS5$`Q28.1_Page Submit`
dataXS6$estimate<-dataXS6$Q29.2_1
dataXS6$value<-2.25
dataXS6$time<-dataXS6$`Q29.1_Page Submit`
dataXS7$estimate<-dataXS7$Q30.2_1
dataXS7$value<-2.5
dataXS7$time<-dataXS7$`Q30.1_Page Submit`
dataXS8$estimate<-dataXS8$Q31.2_1
dataXS8$value<-2.75
dataXS8$time<-dataXS8$`Q31.1_Page Submit`
dataXS9$estimate<-dataXS9$Q32.2_1
dataXS9$value<-3
dataXS9$time<-dataXS9$`Q32.1_Page Submit`
dataXS10$estimate<-dataXS10$Q33.2_1
dataXS10$value<-3.25
dataXS10$time<-dataXS10$`Q33.1_Page Submit`
dataXS11$estimate<-dataXS11$Q34.2_1
dataXS11$value<-3.5
dataXS11$time<-dataXS11$`Q34.1_Page Submit`
dataXS12$estimate<-dataXS12$Q35.2_1
dataXS12$value<-3.75
dataXS12$time<-dataXS12$`Q35.1_Page Submit`
dataXS13$estimate<-dataXS13$Q36.2_1
dataXS13$value<-4
dataXS13$time<-dataXS13$`Q36.1_Page Submit`
dataXS14$estimate<-dataXS14$Q37.2_1
dataXS14$value<-4.25
dataXS14$time<-dataXS14$`Q37.1_Page Submit`
dataXS15$estimate<-dataXS15$Q38.2_1
dataXS15$value<-4.5
dataXS15$time<-dataXS15$`Q38.1_Page Submit`
dataXS16$estimate<-dataXS16$Q39.2_1
dataXS16$value<-4.75
dataXS16$time<-dataXS16$`Q39.1_Page Submit`
dataXS17$estimate<-dataXS17$Q40.2_1
dataXS17$value<-5
dataXS17$time<-dataXS17$`Q40.1_Page Submit`
dataXN1$estimate<-dataXN1$Q42.2_1
dataXN1$value<-1
dataXN1$time<-dataXN1$`Q42.1_Page Submit`
dataXN2$estimate<-dataXN2$Q43.2_1
dataXN2$value<-1.25
dataXN2$time<-dataXN2$`Q43.1_Page Submit`
dataXN3$estimate<-dataXN3$Q44.2_1
dataXN3$value<-1.5
dataXN3$time<-dataXN3$`Q44.1_Page Submit`
dataXN4$estimate<-dataXN4$Q45.2_1
dataXN4$value<-1.75
dataXN4$time<-dataXN4$`Q45.1_Page Submit`
dataXN5$estimate<-dataXN5$Q46.2_1
dataXN5$value<-2
dataXN5$time<-dataXN5$`Q46.1_Page Submit`
dataXN6$estimate<-dataXN6$Q47.2_1
dataXN6$value<-2.25
dataXN6$time<-dataXN6$`Q47.1_Page Submit`
dataXN7$estimate<-dataXN7$Q48.2_1
dataXN7$value<-2.5
dataXN7$time<-dataXN7$`Q48.1_Page Submit`
dataXN8$estimate<-dataXN8$Q49.2_1
dataXN8$value<-2.75
dataXN8$time<-dataXN8$`Q49.1_Page Submit`
dataXN9$estimate<-dataXN9$Q50.2_1
dataXN9$value<-3
dataXN9$time<-dataXN9$`Q50.1_Page Submit`
dataXN10$estimate<-dataXN10$Q51.2_1
dataXN10$value<-3.25
dataXN10$time<-dataXN10$`Q51.1_Page Submit`
dataXN11$estimate<-dataXN11$Q52.2_1
dataXN11$value<-3.5
dataXN11$time<-dataXN11$`Q51.1_Page Submit`
dataXN12$estimate<-dataXN12$Q53.2_1
dataXN12$value<-3.75
dataXN12$time<-dataXN12$`Q53.1_Page Submit`
dataXN13$estimate<-dataXN13$Q54.2_1
dataXN13$value<-4
dataXN13$time<-dataXN13$`Q54.1_Page Submit`
dataXN14$estimate<-dataXN14$Q55.2_1
dataXN14$value<-4.25
dataXN14$time<-dataXN14$`Q55.1_Page Submit`
dataXN15$estimate<-dataXN15$Q56.2_1
dataXN15$value<-4.5
dataXN15$time<-dataXN15$`Q56.1_Page Submit`
dataXN16$estimate<-dataXN16$Q57.2_1
dataXN16$value<-4.75
dataXN16$time<-dataXN16$`Q57.1_Page Submit`
dataXN17$estimate<-dataXN17$Q58.2_1
dataXN17$value<-5
dataXN17$time<-dataXN17$`Q58.1_Page Submit`
#merging datasets
data_main<-data.table(rbind(dataN1,dataS1,dataN2,dataS2,dataN3,dataS3,dataN4,dataS4,dataN5,dataS5,dataN6,dataS6,dataN7,dataS7,dataN8,dataS8,dataN9,dataS9,dataN10,dataS10,dataN11,dataS11,dataN12,dataS12,dataN13,dataS13,dataN14,dataS14,dataN15,dataS15,dataN16,dataS16,dataN17,dataS17,dataXN1,dataXS1,dataXN2,dataXS2,dataXN3,dataXS3,dataXN4,dataXS4,dataXN5,dataXS5,dataXN6,dataXS6,dataXN7,dataXS7,dataXN8,dataXS8,dataXN9,dataXS9,dataXN10,dataXS10,dataXN11,dataXS11,dataXN12,dataXS12,dataXN13,dataXS13,dataXN14,dataXS14,dataXN15,dataXS15,dataXN16,dataXS16,dataXN17,dataXS17))
#creating deviation variable
data_main$deviation<-data_main$estimate-data_main$value
#creating Number Type variables
data_main$Number_Type<-"Fractional"
data_main[value == 1 |value == 2| value == 3 | value == 4 | value == 5 ]$Number_Type<-"Whole"
data_main$Number_Type_2<-"Whole"
data_main[value == 1.25 |value == 2.25| value == 3.25 | value == 4.25 ]$Number_Type_2<-"Quarter"
data_main[value == 1.5 |value == 2.5| value == 3.5 | value == 4.5 ]$Number_Type_2<-"Half"
data_main[value == 1.75 |value == 2.75| value == 3.75 | value == 4.75 ]$Number_Type_2<-"Three-fourth"
#creating another variable
data_main$VC<-"Whole-ArabicNumerals"
data_main[Number_Type=="Fractional" & Format=="Numeric"]$VC<-"Fractional-ArabicNumerals"
data_main[Number_Type=="Fractional" & Format=="Star"]$VC<-"Fractional-Stars"
data_main[Number_Type=="Whole" & Format=="Star"]$VC<-"Whole-Stars"
#Standardizing the numeric variables, note that all the numeric variables that are standardized begin with upper case letters
#Note that factor variables are not standardized
data_main$Age<-scale(data_main$age)
data_main$LogIncome<-scale(data_main$logincome)
data_main$Education<-scale(data_main$education)
data_main$Years_Education<-scale(data_main$years_education)
data_main$Estimate<-scale(data_main$estimate)
data_main$Deviation<-scale(data_main$deviation)
data_main$Rating_Symbol<-as_factor(data_main$Format)
data_main$Contour<-as_factor(data_main$Contour)
data_main$value<-as.numeric(data_main$value)
data_main$Value<-scale(data_main$value)
data_main$Number_Type<-as_factor(data_main$Number_Type)
data_main$Number_Type_2<-as_factor(data_main$Number_Type_2)
data_main$response_time<-(data_main$time)
data_main$RT<-scale(data_main$response_time)
data_main$log_rt<-log(data_main$response_time)
data_main$VC<-as_factor(data_main$VC)
data_main <- within(data_main, Number_Type <- relevel(Number_Type, ref = "Fractional"))
data_main <- within(data_main, Rating_Symbol <- relevel(Rating_Symbol, ref = "Star"))
levels(data_main$Rating_Symbol)<-c("Star","Arabic Numeral")
data_main <- within(data_main, VC <- relevel(VC, ref = "Whole-Stars"))
data_main <- within(data_main, VC <- relevel(VC, ref = "Fractional-ArabicNumerals"))
data_main <- within(data_main, VC <- relevel(VC, ref = "Fractional-Stars"))
#creating datasets with average deviations for ANOVA analysis
dat_anova<-data_main[, .(deviation = mean(deviation),SD_deviation = sd(deviation),estimate = mean(estimate),SD_estimate = sd(estimate),value=mean(value),.N), by = .(ID, Rating_Symbol, Number_Type, Contour)]
#Age
mean(data_main$age)
median(data_main$age)
#Gender
mean(data_main$Gender)
#Creating new datasets for plots
dat_plot<-data_main[, .(deviation = mean(deviation),SD_deviation = sd(deviation),estimate = mean(estimate),SD_estimate = sd(estimate),value=mean(value),response_time=mean(response_time),.N), by = .(VC,ID, Contour)]
dat_plot2<-data_main[, .(deviation = mean(deviation),SD_deviation = sd(deviation),Estimate = mean(Estimate),SD_estimate = sd(Estimate),Value=mean(Value),response_time=mean(response_time),.N), by = .(Number_Type,ID, Contour, Rating_Symbol)]
levels(dat_plot$Contour)<-c("Visually Incomplete","Visually Complete")
levels(dat_plot2$Contour)<-c("Visually Incomplete","Visually Complete")
levels(dat_plot2$Rating_Symbol)<-c("Fractional Stars","Fractional Arabic Numerals")
dodge_width <- 0.8
dodge_width <- 0.8
x<-ggplot(dat_plot,aes(x=VC, y=deviation,fill=Contour)) +
geom_bar(stat="summary",  position = position_dodge(dodge_width), width = dodge_width)+stat_summary(fun.data=mean_cl_normal,geom="errorbar", position = position_dodge(dodge_width), width=0.3, color="black", size=0.45)+xlab("Number Type - Rating Symbol")+ylab("Deviation in Magnitude (Perceived - Actual)")+theme_minimal()+scale_y_continuous(n.breaks = 8)+scale_fill_manual(values=c("#FBDA44","#878A8B"),name="Type of Stars")+expand_limits(y=c(-.15, .15))+ theme(text = element_text(size = 18))   +theme(axis.text = element_text(size = 11))+theme(legend.position="bottom")+theme(legend.text=element_text(size=14), legend.title=element_text(size=14),panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
ggsave("test.png",x,device=png, dpi=1200)
dodge_width <- 0.6
x<-ggplot(dat_plot,aes(x=VC, y=deviation,fill=Contour)) +
geom_bar(stat="summary",  position = position_dodge(dodge_width), width = dodge_width)+stat_summary(fun.data=mean_cl_normal,geom="errorbar", position = position_dodge(dodge_width), width=0.3, color="black", size=0.45)+xlab("Number Type - Rating Symbol")+ylab("Deviation in Magnitude (Perceived - Actual)")+theme_minimal()+scale_y_continuous(n.breaks = 8)+scale_fill_manual(values=c("#FBDA44","#878A8B"),name="Type of Stars")+expand_limits(y=c(-.15, .15))+ theme(text = element_text(size = 18))   +theme(axis.text = element_text(size = 11))+theme(legend.position="bottom")+theme(legend.text=element_text(size=14), legend.title=element_text(size=14),panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
ggsave("test.png",x,device=png, dpi=1200)
